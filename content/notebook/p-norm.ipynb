{
 "metadata": {
  "name": "",
  "signature": "sha256:97285de85d65affde6bb82733e4e7178e1e075070a4c71ed5f5f5b0814fe43c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Numerically-stable p-norms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the p-norm\n",
      "$$\n",
      "|| \\boldsymbol{x} ||_p = \\left( \\sum_i |x_i|^p \\right)^{\\frac{1}{p}}\n",
      "$$\n",
      "\n",
      "In python this translates to:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import array\n",
      "\n",
      "def norm1(x, p):\n",
      "    \"First-pass implementation of p-norm.\"\n",
      "    return (x**p).sum() ** (1./p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, suppose $|x_i|^p$ causes overflow (for some $i$). This will occur for sufficiently large $p$ or sufficiently large $x_i$---even if $x_i$ is representable (i.e., not NaN or $\\infty$).\n",
      "\n",
      "For example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big = 1e300\n",
      "x = array([big])\n",
      "\n",
      "print 'got: %g' % norm1(x, p=2)\n",
      "print 'expected: %g' % big"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "got: inf\n",
        "expected: 1e+300\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This fails because we can't square big"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.array([big])**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ inf]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A little math"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a way to avoid overflow on the account of a few large $x_i$.\n",
      "\n",
      "Here's a little fact about p-norms: for any $p$ and $\\boldsymbol{x}$\n",
      "$$\n",
      "|| \\alpha \\cdot \\boldsymbol{x} ||_p = |\\alpha| \\cdot || \\boldsymbol{x}   ||_p\n",
      "$$\n",
      "\n",
      "We'll use the following version (harder to remember)\n",
      "$$\n",
      "|| \\boldsymbol{x} ||_p  = |\\alpha| \\cdot || \\boldsymbol{x} / \\alpha ||_p\n",
      "$$\n",
      "\n",
      "Don't believe it? Here's some algebra:\n",
      "$$\n",
      "\\begin{eqnarray*}\n",
      "|| \\boldsymbol{x} ||_p\n",
      "&=& \\left( \\sum_i |x_i|^p \\right)^{\\frac{1}{p}} \\\\\n",
      "&=& \\left( \\sum_i \\frac{|\\alpha|^p}{|\\alpha|^p} \\cdot |x_i|^p \\right)^{\\frac{1}{p}} \\\\\n",
      "&=& |\\alpha| \\cdot \\left( \\sum_i \\left( \\frac{|x_i| }{|\\alpha|} \\right)^p \\right)^{\\frac{1}{p}} \\\\\n",
      "&=& |\\alpha| \\cdot \\left( \\sum_i \\left| \\frac{x_i }{\\alpha} \\right|^p \\right)^{\\frac{1}{p}} \\\\\n",
      "&=& |\\alpha| \\cdot || \\boldsymbol{x} / \\alpha ||_p\n",
      "\\end{eqnarray*}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Back to numerical stability"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we pick $\\alpha = \\max_i |x_i|$. Now, the largest number we have to take\n",
      "the power of is one --- making it very difficult to overflow to the account of\n",
      "$\\boldsymbol{x}$. This should remind you of the infamous log-sum-exp trick."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def robust_norm(x, p):\n",
      "    a = np.abs(x).max()\n",
      "    return a * norm1(x / a, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, our example from before works :-)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print robust_norm(x, p=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1e+300\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Remarks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "* A special case of this trick is available for $p=2$ (Euclidean norm), c.f `numpy.hypot`.\n",
      "\n",
      "* It appears as if `scipy.linalg.norm` is stable while `numpy.linalg.norm` is not. Note that `scipy.linalg.norm` appears to be a bit slower.\n",
      "\n",
      "* `logsumexp` an nearly identical trick, but operates in the log-domain, i.e., $\\log(|| \\log(|x|) ||_p)$. You can implement both tricks with the same code, if you use different number classes for log-domain and real-domain---a trick you might have seen before."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}